{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import metrics, activations, initializers, regularizers, constraints\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Reshape, Permute, Activation, \\\n",
    "    Input, Lambda, Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data, base_types):\n",
    "    new_data = np.zeros((len(data),len(data[0,1])))\n",
    "    for idx,i in zip(data[:,0],data[:,1]):\n",
    "        new_data[idx] = [base_types[j]  for j in i]\n",
    "    return new_data\n",
    "\n",
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        base_types = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "        self._data = preprocess(data.values, base_types)\n",
    "        if data.values.shape[1] == 3:\n",
    "            self._labels = data.values[:,2]\n",
    "        else:\n",
    "            self._labels = None\n",
    "            \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "    \n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.4000 - acc: 0.8090 - val_loss: 0.3572 - val_acc: 0.8750\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 679us/step - loss: 0.3465 - acc: 0.8530 - val_loss: 0.2429 - val_acc: 0.9150\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 686us/step - loss: 0.3319 - acc: 0.8635 - val_loss: 0.2832 - val_acc: 0.9050\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 677us/step - loss: 0.3287 - acc: 0.8610 - val_loss: 0.4282 - val_acc: 0.8550\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 686us/step - loss: 0.3114 - acc: 0.8770 - val_loss: 0.1033 - val_acc: 0.9600\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 681us/step - loss: 0.3213 - acc: 0.8725 - val_loss: 0.3691 - val_acc: 0.8650\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 686us/step - loss: 0.3183 - acc: 0.8705 - val_loss: 0.4200 - val_acc: 0.8500\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 684us/step - loss: 0.3036 - acc: 0.8730 - val_loss: 0.2567 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 690us/step - loss: 0.3121 - acc: 0.8660 - val_loss: 0.3557 - val_acc: 0.8800\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 683us/step - loss: 0.3051 - acc: 0.8810 - val_loss: 0.4385 - val_acc: 0.8400\n",
      "Test loss: 0.438507359028\n",
      "Test accuracy: 0.84\n",
      "400/400 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "data_dir = \".\"\n",
    "train_file = os.path.join(data_dir,\"train.csv\")\n",
    "test_file = os.path.join(data_dir,\"test.csv\")\n",
    "train_data = Dataset(train_file)\n",
    "test_data = Dataset(test_file)\n",
    "\n",
    "x_train = train_data.data\n",
    "y_train = train_data.labels\n",
    "\n",
    "#model settings\n",
    "batch_size = 10\n",
    "num_classes = 1\n",
    "num_base_types = 4\n",
    "epochs = 10\n",
    "cutoff_len = int(0.9 * len(train_data.data))\n",
    "\n",
    "# inputs dimensions\n",
    "seq_len, emb_dim = 14, 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_base_types+1, output_dim=emb_dim, input_length=seq_len))\n",
    "model.add(Conv1D(32, kernel_size=2, activation='relu'))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.rmsprop(), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_train[cutoff_len:], y_train[cutoff_len:]))\n",
    "score = model.evaluate(x_train[cutoff_len:], y_train[cutoff_len:], verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "predictions = np.zeros((test_data.data.shape[0],2))\n",
    "test = model.predict(test_data.data, batch_size=batch_size, verbose=1)\n",
    "\n",
    "for idx,p in enumerate(test):\n",
    "    predictions[idx,0] = idx\n",
    "    if p > 0.5:\n",
    "        predictions[idx,1] = 1\n",
    "    else:\n",
    "        predictions[idx,1] = 0 \n",
    "\n",
    "with open(\"submission.csv\",\"wb\") as f:\n",
    "        np.savetxt(f, predictions, fmt='%d',delimiter=',',header=\"id,prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
